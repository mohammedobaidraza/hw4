# -*- coding: utf-8 -*-
"""HW4.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1DObfEAE2ziMCuy4nqumQF6JBte8Cuv1I

**Titanic**
"""

import pandas as pd
import numpy as np

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, LabelEncoder
#Titanic dataset path
train_df = pd.read_csv('/content/drive/MyDrive/ML/titanic dataset/train.csv')

#Filling missing values in 'Age' and 'Embarked' columns without chaining assignments
train_df['Age'] = train_df['Age'].fillna(train_df['Age'].median())
train_df['Embarked'] = train_df['Embarked'].fillna(train_df['Embarked'].mode()[0])

# Encoded categorical variables
label_enc = LabelEncoder()
train_df['Sex'] = label_enc.fit_transform(train_df['Sex'])  # male=1, female=0
train_df['Embarked'] = label_enc.fit_transform(train_df['Embarked'])

#Setting features and target variable
features = ['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Embarked']
X = train_df[features]
y = train_df['Survived']

#Spliting into training (80%) and test sets (20%)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

#Standardize features
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

#Custom 5-fold cross-validation function
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score

def n_fold_cross_validation(X, y, model, n_splits=5):
    fold_size = len(X) // n_splits
    accuracies = []

    for i in range(n_splits):
        start, end = i * fold_size, (i + 1) * fold_size
        X_val, y_val = X[start:end], y[start:end]
        X_train_fold = np.concatenate((X[:start], X[end:]))
        y_train_fold = np.concatenate((y[:start], y[end:]))

        #Model accuracy on validation set
        model.fit(X_train_fold, y_train_fold)
        y_pred = model.predict(X_val)
        accuracies.append(accuracy_score(y_val, y_pred))

    return np.mean(accuracies)

#Logistic regression model
logistic_model = LogisticRegression(max_iter=1000, solver='liblinear')
cross_val_accuracy = n_fold_cross_validation(X_train, y_train, logistic_model, n_splits=5)
print("Logistic Regression Cross-Validation Accuracy:", cross_val_accuracy)

from sklearn.svm import SVC
C_values = [0.1, 1, 10]

#Logistic Regression
logistic_results = []
for C in C_values:
    logistic_model = LogisticRegression(C=C, max_iter=1000, solver='liblinear')
    accuracy = n_fold_cross_validation(X_train, y_train, logistic_model, n_splits=5)
    logistic_results.append((C, accuracy))

#Best parameter for logistic regression
best_logistic = max(logistic_results, key=lambda x: x[1])
print("Best Logistic Regression (C):", best_logistic[0], "Accuracy:", best_logistic[1])

#SVM with linear kernel
svm_results = []
for C in C_values:
    svm_model = SVC(C=C, kernel='linear')
    accuracy = n_fold_cross_validation(X_train, y_train, svm_model, n_splits=5)
    svm_results.append((C, accuracy))

#Finding the best parameter for SVM
best_svm = max(svm_results, key=lambda x: x[1])
print("Best SVM (C):", best_svm[0], "Accuracy:", best_svm[1])

from sklearn.linear_model import LogisticRegression
from sklearn.svm import SVC
from sklearn.metrics import accuracy_score

#Logistic Regression model on the test set
best_logistic_regression_model = LogisticRegression(C=best_logistic[0], max_iter=1000, solver='liblinear')
best_logistic_regression_model.fit(X_train, y_train)
logistic_regression_test_accuracy = accuracy_score(y_test, best_logistic_regression_model.predict(X_test))

#SVM model on the test set
best_svm_model = SVC(C=best_svm[0], kernel='linear')
best_svm_model.fit(X_train, y_train)
svm_test_accuracy = accuracy_score(y_test, best_svm_model.predict(X_test))

print("Logistic Regression - Test Accuracy:", logistic_regression_test_accuracy)
print("SVM - Test Accuracy:", svm_test_accuracy)
#Logistic Regression for cross-validation
def n_fold_cross_validation(X, y, model, n_splits=5):
    fold_size = len(X) // n_splits
    accuracies = []

    for i in range(n_splits):
        start, end = i * fold_size, (i + 1) * fold_size
        X_val, y_val = X[start:end], y[start:end]
        X_train_fold = np.concatenate((X[:start], X[end:]))
        y_train_fold = np.concatenate((y[:start], y[end:]))

        #Training the model and calculate accuracy on validation set
        model.fit(X_train_fold, y_train_fold)
        y_pred = model.predict(X_val)
        accuracies.append(accuracy_score(y_val, y_pred))

    return np.mean(accuracies)

#Logistic Regression Cross-Validation Accuracy
cross_val_accuracy = n_fold_cross_validation(X_train, y_train, logistic_model, n_splits=5)
print("Logistic Regression Cross-Validation Accuracy:", cross_val_accuracy)

